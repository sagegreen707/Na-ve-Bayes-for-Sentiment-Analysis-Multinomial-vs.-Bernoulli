{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All necessary libraries for this assignment have already been added. You are not allowed to add any additional imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.10/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install nltk\n",
    "# !pip install datasets\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/macbook/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from datasets import load_dataset\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "# Bernoulli Naive Bayes\n",
    "golf_data = pd.read_csv('/Users/macbook/Desktop/semester 5/ML/PA1/golf_data.csv')  # Replace with correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0178461ed06d4094a182f3e58db6f68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06ba7bd122d41b7aada9842b89e18c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75563aefaaf84e459d6aa34061572a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  â€œWorry is a down payment on a problem you may ...      2\n",
      "1  My roommate: it's okay that we can't spell bec...      0\n",
      "2  No but that's so cute. Atsu was probably shy a...      1\n",
      "3  Rooneys fucking untouchable isn't he? Been fuc...      0\n",
      "4  it's pretty depressing when u hit pan on ur fa...      3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "emotion_labels = {\n",
    "    0: 'anger',\n",
    "    1: 'joy',\n",
    "    2: 'optimism',\n",
    "    3: 'sadness'\n",
    "}\n",
    "\n",
    "tweet_data = load_dataset('tweet_eval', 'emotion', cache_dir=\"datasets\")\n",
    "\n",
    "def convert_to_dataframe(split):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for entry in tweet_data[split]:\n",
    "        text = entry['text']\n",
    "        label = entry['label']\n",
    "        \n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "    \n",
    "    df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "    return df\n",
    "\n",
    "train_df = convert_to_dataframe('train')\n",
    "val_df = convert_to_dataframe('validation')\n",
    "test_df = convert_to_dataframe('test')\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before proceeding with further tasks, ensure you have determined which type of Naive Bayes is most suitable for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing the Golf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Golf Dataset:\n",
      "   Holiday   Month  Season Temperature Humidity  Windy Outlook Crowdedness  \\\n",
      "0        1  Winter  Winter         low      low      1   sunny        high   \n",
      "1        1  Winter  Winter         low      low      1   sunny        high   \n",
      "2        1  Winter  Winter         low      low      1   sunny        high   \n",
      "3        1  Winter  Winter         low      low      1   sunny        high   \n",
      "4        1  Winter  Winter         low      low      1   sunny        high   \n",
      "\n",
      "   Play  \n",
      "0     1  \n",
      "1     0  \n",
      "2     0  \n",
      "3     1  \n",
      "4     1  \n",
      "\n",
      "Encoded Golf Dataset:\n",
      "   Holiday  month_winter  season_winter  temperature_high  humidity_high  \\\n",
      "0        1             1              1                 0              0   \n",
      "1        1             1              1                 0              0   \n",
      "2        1             1              1                 0              0   \n",
      "3        1             1              1                 0              0   \n",
      "4        1             1              1                 0              0   \n",
      "\n",
      "   windy  outlook_sunny  crowded_high  Play  \n",
      "0      1              1             1     1  \n",
      "1      1              1             1     0  \n",
      "2      1              1             1     0  \n",
      "3      1              1             1     1  \n",
      "4      1              1             1     1  \n",
      "\n",
      "Training set shape: (5365, 8) (5365,)\n",
      "Test set shape: (2300, 8) (2300,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = '/Users/macbook/Desktop/semester 5/ML/PA1/golf_data.csv'\n",
    "golf_data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Initial Golf Dataset:\")\n",
    "print(golf_data.head())\n",
    "\n",
    "month_map = {'Winter': 1, 'Non-Winter': 0}\n",
    "golf_data['Month'] = golf_data['Month'].map(month_map)\n",
    "\n",
    "season_map = {'Winter': 1, 'Non-Winter': 0}\n",
    "golf_data['Season'] = golf_data['Season'].map(season_map)\n",
    "\n",
    "golf_data.rename(columns={'Month': 'month_winter', 'Season': 'season_winter'}, inplace=True)\n",
    "\n",
    "temperature_map = {'high': 1, 'low': 0}\n",
    "golf_data['Temperature'] = golf_data['Temperature'].map(temperature_map)\n",
    "\n",
    "humidity_map = {'high': 1, 'low': 0}\n",
    "golf_data['Humidity'] = golf_data['Humidity'].map(humidity_map)\n",
    "\n",
    "golf_data.rename(columns={'Temperature': 'temperature_high', 'Humidity': 'humidity_high'}, inplace=True)\n",
    "\n",
    "golf_data.rename(columns={'Windy': 'windy'}, inplace=True)\n",
    "\n",
    "outlook_map = {'sunny': 1, 'not sunny': 0}\n",
    "golf_data['Outlook'] = golf_data['Outlook'].map(outlook_map)\n",
    "\n",
    "golf_data.rename(columns={'Outlook': 'outlook_sunny'}, inplace=True)\n",
    "\n",
    "crowdedness_map = {'high': 1, 'not high': 0}\n",
    "golf_data['Crowdedness'] = golf_data['Crowdedness'].map(crowdedness_map)\n",
    "\n",
    "golf_data.rename(columns={'Crowdedness': 'crowded_high'}, inplace=True)\n",
    "\n",
    "print(\"\\nEncoded Golf Dataset:\")\n",
    "print(golf_data.head())\n",
    "\n",
    "X = golf_data.drop('Play', axis=1)\n",
    "y = golf_data['Play']\n",
    "\n",
    "test_size = 0.3\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(\"\\nTraining set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# golf_data.to_csv('/Users/macbook/Desktop/semester 5/ML/PA1/golf_data_encoded.csv', index=False)\n",
    "# print(\"\\nEncoded Golf Dataset saved to 'golf_data_encoded.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing the Tweet Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      "Cleaning training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbook/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/macbook/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning validation data...\n",
      "Cleaning test data...\n",
      "\n",
      "Original vs Cleaned Text in Training Data:\n",
      "                                                text  \\\n",
      "0  â€œWorry is a down payment on a problem you may ...   \n",
      "1  My roommate: it's okay that we can't spell bec...   \n",
      "2  No but that's so cute. Atsu was probably shy a...   \n",
      "3  Rooneys fucking untouchable isn't he? Been fuc...   \n",
      "4  it's pretty depressing when u hit pan on ur fa...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  worry payment problem may never joyce meyer mo...  \n",
      "1  roommate okay cant spell autocorrect terrible ...  \n",
      "2  thats cute atsu probably shy photo cherry help...  \n",
      "3  rooneys fucking untouchable isnt fucking dread...  \n",
      "4  pretty depressing u hit pan ur favourite highl...  \n",
      "\n",
      "Column names in Training DataFrame:\n",
      "Index(['text', 'label', 'cleaned_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "print(\"Downloading NLTK resources...\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    url_pattern = r'http\\S+|www\\S+|https\\S+'\n",
    "    text = re.sub(url_pattern, '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    mention_pattern = r'@\\w+'\n",
    "    text = re.sub(mention_pattern, '', text)\n",
    "    \n",
    "    non_alphanumeric_pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(non_alphanumeric_pattern, '', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    whitespace_pattern = r'\\s+'\n",
    "    text = re.sub(whitespace_pattern, ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"Cleaning training data...\")\n",
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Cleaning validation data...\")\n",
    "val_df['cleaned_text'] = val_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Cleaning test data...\")\n",
    "test_df['cleaned_text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"\\nOriginal vs Cleaned Text in Training Data:\")\n",
    "print(train_df[['text', 'cleaned_text']].head())\n",
    "\n",
    "print(\"\\nColumn names in Training DataFrame:\")\n",
    "print(train_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Naive Bayes from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = None\n",
    "        self.conditional_probs = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        self.class_priors = np.zeros(n_classes)\n",
    "        self.conditional_probs = np.zeros((n_classes, n_features))\n",
    "\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.class_priors[idx] = X_c.shape[0] / n_samples\n",
    "            numerator = X_c.sum(axis=0) + 1\n",
    "            denominator = X_c.shape[0] + 2\n",
    "            self.conditional_probs[idx, :] = numerator / denominator\n",
    "\n",
    "    def predict(self, X):\n",
    "        log_class_priors = np.log(self.class_priors)\n",
    "        log_conditional_probs = np.log(self.conditional_probs.T)\n",
    "        log_complementary_probs = np.log(1 - self.conditional_probs.T)\n",
    "        log_probs = log_class_priors + X @ log_conditional_probs + (1 - X) @ log_complementary_probs\n",
    "        predicted_classes = np.argmax(log_probs, axis=1)\n",
    "        return self.classes[predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bernoulli Naive Bayes for Test Dataset - Golf\n",
      "\n",
      "Accuracy: 0.8200\n",
      "Precision: 0.7685\n",
      "Recall: 0.8200\n",
      "F1 Score: 0.7494\n",
      "Confusion Matrix:\n",
      "[[1872   13]\n",
      " [ 401   14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "bnb_model = BernoulliNaiveBayes()\n",
    "bnb_model.fit(X_train.values, y_train.values)\n",
    "\n",
    "y_pred_val = bnb_model.predict(X_test.values)\n",
    "\n",
    "accuracy_val = accuracy_score(y_test.values, y_pred_val)\n",
    "precision_val = precision_score(y_test.values, y_pred_val, average='weighted')\n",
    "recall_val = recall_score(y_test.values, y_pred_val, average='weighted')\n",
    "f1_val = f1_score(y_test.values, y_pred_val, average='weighted')\n",
    "confusion_val = confusion_matrix(y_test.values, y_pred_val)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Bernoulli Naive Bayes for Test Dataset - Golf\\n\")\n",
    "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Precision: {precision_val:.4f}\")\n",
    "print(f\"Recall: {recall_val:.4f}\")\n",
    "print(f\"F1 Score: {f1_val:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Multinomial Naive Bayes (Manual Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BagOfWords:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = {}\n",
    "        self.word_to_index = {}\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        unique_words = set()\n",
    "        for sentence in corpus:\n",
    "            words_in_sentence = sentence.split()\n",
    "            unique_words.update(words_in_sentence)\n",
    "        \n",
    "        self.vocabulary = sorted(unique_words)\n",
    "        self.word_to_index = {word: idx for idx, word in enumerate(self.vocabulary)}\n",
    "    \n",
    "    def vectorize(self, sentence):\n",
    "        vector_length = len(self.vocabulary)\n",
    "        vector = np.zeros(vector_length, dtype=int)\n",
    "        words_in_sentence = sentence.split()\n",
    "        \n",
    "        for word in words_in_sentence:\n",
    "            if word in self.word_to_index:\n",
    "                index = self.word_to_index[word]\n",
    "                vector[index] += 1\n",
    "        \n",
    "        return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the cat sat on the mat\n",
      "Vocabulary: ['the', 'cat', 'sat', 'on', 'mat']\n",
      "Word-to-index mapping: {'the': 0, 'cat': 1, 'sat': 2, 'on': 3, 'mat': 4}\n",
      "Vectorized form: [2 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "vocabulary = [\"the\", \"cat\", \"sat\", \"on\", \"mat\"]\n",
    "\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "vector = np.zeros(len(vocabulary), dtype=int)\n",
    "\n",
    "sentence = \"the cat sat on the mat\"\n",
    "\n",
    "for word in sentence.split():\n",
    "    if word in word_to_index:\n",
    "        index = word_to_index[word]\n",
    "        vector[index] += 1\n",
    "\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Vocabulary: {vocabulary}\")\n",
    "print(f\"Word-to-index mapping: {word_to_index}\")\n",
    "print(f\"Vectorized form: {vector}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.logprior = None\n",
    "        self.loglikelihood = None\n",
    "        self.vocabulary = None\n",
    "        self.classes = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        num_docs = len(y)\n",
    "        self.classes = np.unique(y)\n",
    "        num_classes = len(self.classes)\n",
    "        self.logprior = np.zeros(num_classes)\n",
    "        self.loglikelihood = np.zeros((X.shape[1], num_classes))\n",
    "        self.vocabulary = X.shape[1]\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            Nc = np.sum(y == c)\n",
    "            self.logprior[idx] = np.log(Nc) - np.log(num_docs)\n",
    "            bigdoc_c = X[y == c]\n",
    "            word_counts = np.sum(bigdoc_c, axis=0)\n",
    "            total_count_c = np.sum(word_counts)\n",
    "            \n",
    "            for w in range(X.shape[1]):\n",
    "                word_prob = (word_counts[w] + 1) / (total_count_c + self.vocabulary)\n",
    "                self.loglikelihood[w, idx] = np.log(word_prob)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_docs = X.shape[0]\n",
    "        scores = np.zeros((num_docs, len(self.classes)))\n",
    "\n",
    "        for c_idx, c in enumerate(self.classes):\n",
    "            scores[:, c_idx] = self.logprior[c_idx] + np.dot(X, self.loglikelihood[:, c_idx])\n",
    "\n",
    "        predicted_classes = self.classes[np.argmax(scores, axis=1)]\n",
    "        return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes for Twitter Dataset - Validation Results\n",
      "\n",
      "Accuracy: 0.6791\n",
      "Precision: 0.6888\n",
      "Recall: 0.6791\n",
      "F1 Score: 0.6565\n",
      "Confusion Matrix:\n",
      "[[145   5   1   9]\n",
      " [ 30  50   1  16]\n",
      " [ 13   4   4   7]\n",
      " [ 29   5   0  55]]\n",
      "\n",
      "Naive Bayes for Twitter Dataset - Test Results\n",
      "\n",
      "Accuracy: 0.6615\n",
      "Precision: 0.6726\n",
      "Recall: 0.6615\n",
      "F1 Score: 0.6398\n",
      "Confusion Matrix:\n",
      "[[493  22   2  41]\n",
      " [107 185   5  61]\n",
      " [ 67  13  18  25]\n",
      " [114  20   4 244]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_df['cleaned_text']).toarray()\n",
    "val_vectors = vectorizer.transform(val_df['cleaned_text']).toarray()\n",
    "test_vectors = vectorizer.transform(test_df['cleaned_text']).toarray()\n",
    "\n",
    "nb_model = NaiveBayes()\n",
    "nb_model.train(train_vectors, train_df['label'].values)\n",
    "\n",
    "val_predictions = nb_model.predict(val_vectors)\n",
    "accuracy_val = accuracy_score(val_df['label'].values, val_predictions)\n",
    "precision_val = precision_score(val_df['label'].values, val_predictions, average='weighted')\n",
    "recall_val = recall_score(val_df['label'].values, val_predictions, average='weighted')\n",
    "f1_val = f1_score(val_df['label'].values, val_predictions, average='weighted')\n",
    "confusion_val = confusion_matrix(val_df['label'].values, val_predictions)\n",
    "\n",
    "print(\"\\nNaive Bayes for Twitter Dataset - Validation Results\\n\")\n",
    "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Precision: {precision_val:.4f}\")\n",
    "print(f\"Recall: {recall_val:.4f}\")\n",
    "print(f\"F1 Score: {f1_val:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_val)\n",
    "\n",
    "test_predictions = nb_model.predict(test_vectors)\n",
    "accuracy_test = accuracy_score(test_df['label'].values, test_predictions)\n",
    "precision_test = precision_score(test_df['label'].values, test_predictions, average='weighted')\n",
    "recall_test = recall_score(test_df['label'].values, test_predictions, average='weighted')\n",
    "f1_test = f1_score(test_df['label'].values, test_predictions, average='weighted')\n",
    "confusion_test = confusion_matrix(test_df['label'].values, test_predictions)\n",
    "\n",
    "print(\"\\nNaive Bayes for Twitter Dataset - Test Results\\n\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1 Score: {f1_test:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing Naive Bayes using sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Multinomial Naive Bayes for Validation Dataset - TWITTER DATASET\n",
      "\n",
      "Accuracy (sklearn): 0.6791\n",
      "Precision (sklearn): 0.6888\n",
      "Recall (sklearn): 0.6791\n",
      "F1 Score (sklearn): 0.6565\n",
      "Confusion Matrix (sklearn):\n",
      "[[145   5   1   9]\n",
      " [ 30  50   1  16]\n",
      " [ 13   4   4   7]\n",
      " [ 29   5   0  55]]\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes for Test Dataset - TWITTER DATASET\n",
      "\n",
      "Accuracy (sklearn): 0.6615\n",
      "Precision (sklearn): 0.6726\n",
      "Recall (sklearn): 0.6615\n",
      "F1 Score (sklearn): 0.6398\n",
      "Confusion Matrix (sklearn):\n",
      "[[493  22   2  41]\n",
      " [107 185   5  61]\n",
      " [ 67  13  18  25]\n",
      " [114  20   4 244]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "nb_model_sklearn = MultinomialNB()\n",
    "nb_model_sklearn.fit(train_vectors, train_df['label'].values)\n",
    "\n",
    "val_predictions_sklearn = nb_model_sklearn.predict(val_vectors)\n",
    "\n",
    "accuracy_sklearn = accuracy_score(val_df['label'].values, val_predictions_sklearn)\n",
    "precision_sklearn = precision_score(val_df['label'].values, val_predictions_sklearn, average='weighted')\n",
    "recall_sklearn = recall_score(val_df['label'].values, val_predictions_sklearn, average='weighted')\n",
    "f1_sklearn = f1_score(val_df['label'].values, val_predictions_sklearn, average='weighted')\n",
    "confusion_sklearn = confusion_matrix(val_df['label'].values, val_predictions_sklearn)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Multinomial Naive Bayes for Validation Dataset - TWITTER DATASET\\n\")\n",
    "print(f\"Accuracy (sklearn): {accuracy_sklearn:.4f}\")\n",
    "print(f\"Precision (sklearn): {precision_sklearn:.4f}\")\n",
    "print(f\"Recall (sklearn): {recall_sklearn:.4f}\")\n",
    "print(f\"F1 Score (sklearn): {f1_sklearn:.4f}\")\n",
    "print(\"Confusion Matrix (sklearn):\")\n",
    "print(confusion_sklearn)\n",
    "\n",
    "test_predictions_sklearn = nb_model_sklearn.predict(test_vectors)\n",
    "\n",
    "accuracy_test = accuracy_score(test_df['label'].values, test_predictions_sklearn)\n",
    "precision_test = precision_score(test_df['label'].values, test_predictions_sklearn, average='weighted')\n",
    "recall_test = recall_score(test_df['label'].values, test_predictions_sklearn, average='weighted')\n",
    "f1_test = f1_score(test_df['label'].values, test_predictions_sklearn, average='weighted')\n",
    "confusion_test = confusion_matrix(test_df['label'].values, test_predictions_sklearn)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Multinomial Naive Bayes for Test Dataset - TWITTER DATASET\\n\")\n",
    "print(f\"Accuracy (sklearn): {accuracy_test:.4f}\")\n",
    "print(f\"Precision (sklearn): {precision_test:.4f}\")\n",
    "print(f\"Recall (sklearn): {recall_test:.4f}\")\n",
    "print(f\"F1 Score (sklearn): {f1_test:.4f}\")\n",
    "print(\"Confusion Matrix (sklearn):\")\n",
    "print(confusion_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bernoulli Naive Bayes - GOLF DATASET\n",
      "\n",
      "Accuracy: 0.8200\n",
      "Precision: 0.7685\n",
      "Recall: 0.8200\n",
      "F1 Score: 0.7494\n",
      "Confusion Matrix:\n",
      "[[1872   13]\n",
      " [ 401   14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "bernoulli_nb_model = BernoulliNB()\n",
    "\n",
    "bernoulli_nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bernoulli_nb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Bernoulli Naive Bayes - GOLF DATASET\\n\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected Multinomial Naive Bayes for the Twitter sentiment analysis dataset because it required classifying into four distinct sentiment groups: anger, joy, optimism, and sadness. This algorithm is effective for multi-class problems since it considers the frequency of words within a document to make predictions. This feature is useful for distinguishing between sentiments like joy and optimism, which are both positive emotions. The frequency of words can provide context allowing for more accurate distinctions among these categories. Given that tweets can often be lengthy the occurrences of each word can significantly influence the overall tone and help identify the dominant sentiment. If the task had only involved classifying into positive versus negative emotions, Bernoulli Naive Bayes might have been enough.\n",
    "\n",
    "On the other hand I chose Bernoulli Naive Bayes for the golf dataset because it was designed for making binary predictions: whether or not a person would play golf based on certain factors. The factors in this dataset were also binary (e.g., windy or not windy) so tracking the frequency of word occurrences was unnecessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
